{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The General Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic processes are a pain.\n",
    "\n",
    "1. Random number generation is stochastic.\n",
    "2. Concurrency is stochastic.\n",
    "\n",
    "Concurrent random number generation is double-plus stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Replications of a Stochastic Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    replicate(f::Function, n::Integer)\n",
    "\n",
    "Return a vector of the values of `n` calls to `f()` - used in simulations where the value of `f` is stochastic.\n",
    "\n",
    "\"\"\"\n",
    "function replicate(f::Function, n::Integer)\n",
    "     @showprogress [f() for _ in Base.OneTo(n)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const RNG = MersenneTwister;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onechar() =  randstring(RNG(42), 'a':'z', 1);\n",
    "\n",
    "join(replicate(onechar, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many Random nuber functions are already vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randstring(RNG(42), 'a':'z', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we do we need this?\n",
    "\n",
    "Because we want have many replications of the vectorized operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 samples, each of 180 observations from a normal distribution\n",
    "myrng = RNG(42);\n",
    "samps = replicate(() -> randn(myrng, 180), 10);\n",
    "samps = hcat(samps...);\n",
    "samps[1:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    replicate(f::Function, n::Integer; use_threads=false)\n",
    "\n",
    "Return a vector of the values of `n` calls to `f()` - used in simulations where the value of `f` is stochastic.\n",
    "\n",
    "Note that if `f()` is not thread-safe or depends on a non thread-safe RNG,\n",
    "    then you must set `use_threads=false`. Also note that ordering of replications\n",
    "    is not guaranteed when `use_threads=true`, although the replications are not\n",
    "    otherwise affected for thread-safe `f()`.\n",
    "\"\"\"\n",
    "function replicate(f::Function, n::Integer; use_threads=false)\n",
    "    if use_threads\n",
    "        # no macro version yet: https://github.com/timholy/ProgressMeter.jl/issues/143\n",
    "        p = Progress(n)\n",
    "        # get the type\n",
    "        rr = f()\n",
    "        next!(p)\n",
    "        # pre-allocate\n",
    "        results = [rr for _ in Base.OneTo(n)]\n",
    "        Threads.@threads for idx = 2:n\n",
    "            results[idx] = f()\n",
    "            next!(p)\n",
    "        end\n",
    "    else\n",
    "        results = @showprogress [f() for _ in Base.OneTo(n)]\n",
    "    end\n",
    "    results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrng = RNG(42);\n",
    "st_samps = replicate(() -> randn(myrng, 180), 10; use_threads=true);\n",
    "st_samps = hcat(st_samps...)\n",
    "st_samps[1:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(samps .≈ st_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrng = RNG(42);\n",
    "mt_samps = replicate(() -> randn(myrng, 180), 10; use_threads=true);\n",
    "mt_samps = hcat(mt_samps...)\n",
    "mt_samps[1:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete stream model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(samps .≈ mt_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(sort(reshape(samps, 1800)) .≈ sort(reshape(mt_samps, 1800)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_samps = sort(reshape(samps, 1800));\n",
    "sorted_mt_samps = sort(reshape(mt_samps, 1800));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch =  sorted_samps .≉ sorted_mt_samps;\n",
    "hcat(sorted_samps[mismatch], sorted_mt_samps[mismatch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close, but clearly more than floating point error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? \n",
    "\n",
    "Random number generation is **not** atomic and random generators must be specially constructed to be reentrant. So if you multiple threads are accessing the RNG at the same time, they can run into issues with inconsistent state, thus leading to a different stream. (And this stream may not meet the guarantees normally given by the RNG in question!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add graphics here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a related note, a reproducible stream from a given (pseudo)random number generator may not be reproducible in quite the way you think. While for a given seed, the stream of bits produced from the MersenneTwister should be the same, the way those bits are translated, normalized, etc. to meet the distributional requirements of various methods such as `rand`, `randn`, etc. is not standardized across implementations.\n",
    "\n",
    "In particular, `randn` is only guaranteed to give the same stream for a given seed for a given *minor* release of Julia. For example, `randn(MersenneTwister(42), 100)` will not give the same results on Julia 1.0 and Julia 1.6!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using locks to avoid issues with the RNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function locked_replicate(f::Function, n::Integer; use_threads=false)\n",
    "    if use_threads\n",
    "        rnglock = ReentrantLock()\n",
    "        # no macro version yet: https://github.com/timholy/ProgressMeter.jl/issues/143\n",
    "        p = Progress(n)\n",
    "        # get the type\n",
    "        rr = f()\n",
    "        next!(p)\n",
    "        # pre-allocate\n",
    "        results = [rr for _ in Base.OneTo(n)]\n",
    "        Threads.@threads for idx = 2:n\n",
    "            lock(rnglock)\n",
    "            results[idx] = f()\n",
    "            unlock(rnglock)\n",
    "            next!(p)\n",
    "            sleep(abs(first(results[idx]))) # create some competition\n",
    "        end\n",
    "    else\n",
    "        results = @showprogress [f() for _ in Base.OneTo(n)]\n",
    "    end\n",
    "    results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrng = RNG(42);\n",
    "locked_samps = locked_replicate(() -> randn(myrng, 180), 10; use_threads=true);\n",
    "locked_samps = hcat(locked_samps...)\n",
    "locked_samps[1:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(samps .≈ locked_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(sort(reshape(samps, 1800)) .≈ sort(reshape(locked_samps, 1800)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locking around the entire stochastic function is too much: it effectively reduces to serial execution without ordering guarantees. Instead, locking should be focused around random number generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parametricbootstrap(rng::AbstractRNG, n::Integer, morig::LinearMixedModel{T};\n",
    "    β::AbstractVector=coef(morig),σ=morig.σ, θ::AbstractVector=morig.θ, use_threads::Bool=false) where {T}\n",
    "  \n",
    "    #####\n",
    "    ##### pre allocation and book keeping\n",
    "    #####\n",
    "    \n",
    "    β, σ, θ = convert(Vector{T}, β), T(σ), convert(Vector{T}, θ)\n",
    "    βsc, θsc, p, k, m = similar(β), similar(θ), length(β), length(θ), deepcopy(morig)\n",
    "    β_names = (Symbol.(fixefnames(morig))..., )\n",
    "    rank = length(β_names)\n",
    "\n",
    "    # we need arrays of these for in-place operations to work across threads\n",
    "    m_threads = [m]\n",
    "    βsc_threads = [βsc]\n",
    "    θsc_threads = [θsc]\n",
    "\n",
    "    if use_threads\n",
    "        Threads.resize_nthreads!(m_threads)\n",
    "        Threads.resize_nthreads!(βsc_threads)\n",
    "        Threads.resize_nthreads!(θsc_threads)\n",
    "    end\n",
    "\n",
    "    ##### set up a lock, which will be available via closure\n",
    "    rnglock = ReentrantLock()\n",
    "    \n",
    "    samp = replicate(n, use_threads=use_threads) do\n",
    "        mod = m_threads[Threads.threadid()]\n",
    "        ##### these are local because we're using these same names  in the outer scope\n",
    "        local βsc = βsc_threads[Threads.threadid()]\n",
    "        local θsc = θsc_threads[Threads.threadid()]\n",
    "    \n",
    "        #####\n",
    "        ##### lock only around the stochastic step\n",
    "        #####\n",
    "            \n",
    "        lock(rnglock)\n",
    "        # there are deterministic steps in here, but they're fast\n",
    "        # and finer grain locking would have meant much more complexity \n",
    "        # and book keeping and making an additional function lock- and thread-aware\n",
    "        mod = simulate!(rng, mod, β = β, σ = σ, θ = θ)\n",
    "        unlock(rnglock)\n",
    "        \n",
    "        #####\n",
    "        ##### don't lock around the deterministic manipulation of the stochastic result\n",
    "        #####\n",
    "        \n",
    "        refit!(mod)\n",
    "        \n",
    "        #####\n",
    "        ##### pack all the interesting bits into a Tuple\n",
    "        #####\n",
    "        \n",
    "        (\n",
    "         objective = mod.objective,\n",
    "         σ = mod.σ,\n",
    "         β = NamedTuple{β_names}(fixef!(βsc, mod)),\n",
    "         se = SVector{p,T}(stderror!(βsc, mod)),\n",
    "         θ = SVector{k,T}(getθ!(θsc, mod)),\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    #####\n",
    "    ##### assemble the big struct\n",
    "    #####\n",
    "    \n",
    "    MixedModelBootstrap(\n",
    "        samp,\n",
    "        deepcopy(morig.λ),\n",
    "        getfield.(morig.reterms, :inds),\n",
    "        copy(morig.optsum.lowerbd),\n",
    "        NamedTuple{Symbol.(fnames(morig))}(map(t -> (t.cnames...,), morig.reterms)),\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MixedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form =  @formula(rt_trunc ~ 1 + spkr * prec * load + (1 + spkr + prec + load | subj) +  (1 + spkr + prec + load | item))\n",
    "mod = fit(MixedModel, form, MixedModels.dataset(:kb07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MixedModels.parametricbootstrap(RNG(42), 1, mod);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time st_bsam = MixedModels.parametricbootstrap(RNG(42), 100, mod; use_threads=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time mt_bsam = MixedModels.parametricbootstrap(RNG(42), 100, mod; use_threads=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our tests\n",
    "using Test, Tables\n",
    "\n",
    "@testset \"same results no matter how many threads\" begin\n",
    "    @test sort(mt_bsam.σ) == sort(st_bsam.σ)\n",
    "    @test sort(mt_bsam.θ) == sort(st_bsam.θ)\n",
    "    @test sort(columntable(mt_bsam.β).β) == sort(columntable(st_bsam.β).β)\n",
    "    @test sum(issingular(mt_bsam)) == sum(issingular(st_bsam))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons and Tips\n",
    "\n",
    "\n",
    "## Sharing a RNG between threads is tricky.\n",
    "- RNGs are often not re-entrant\n",
    "- Even if we assume that the individual values are produced atomically the sequence of threads is not guaranteed to be the same across runs, resulting in threads seeing different subsequences from the RNG stream ('striping'). \n",
    "\n",
    "## Locks are one good solution \n",
    "- Locking just the random number generation itself and not computations building upon it.\n",
    "- *All* random number generation for a given stochastic function should be performed at once, if some of the results aren't used until much later. This avoids striping.\n",
    "- This approach can also be extended to `@distributed` multi-processing, but shared objects are somewhat trickier.\n",
    "- This approach yields the same results regardless of the number of threads.\n",
    "- But it relies on the assumption that the RNG is the small part of total computation.\n",
    "- Be very careful when sharing objects between threads that do operations in place!\n",
    "\n",
    "## Alternatives\n",
    "\n",
    "### Distinct RNGs for each thread\n",
    "- You can use different RNGs for each thread, but they should be distinct!\n",
    "- For example, each thread's RNG coudl be seeded using pulls from the first thread's RNG.\n",
    "- Advantage: easy to implement, no locking overhead\n",
    "- Disadvantage: results are dependent on both the original seed and the number of threads.\n",
    "\n",
    "\n",
    "### 'Fast-forwarding' the current RNG \n",
    "- `Future.randjump(r::MersenneTwister, steps::Integer)`\n",
    "  > Create an initialized MersenneTwister object, whose state is moved forward (without generating numbers) from r by steps steps. One such step corresponds to the generation of two Float64 numbers. For each different value of steps, a large polynomial has to be generated internally. One is already pre-computed for steps=big(10)^20.'\n",
    "- Advantage: easy to do \n",
    "- Advantage: same results for arbitrary number of threads *if* you precompute the offsets\n",
    "- Disadvantage: potentially a lot of bookkeeping ahead of time\n",
    "- Disadvantage: still involves computing a large polynomial\n",
    "- Disadvantage: not available for arbitrary RNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work was supported by the Center for Interdisciplinary Research, Bielefeld (ZiF),  Cooperation Group \"Statistical models for psychological and linguistic data\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
